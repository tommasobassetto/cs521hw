{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h753Bwl9egnd",
        "outputId": "4c4d7eef-7309-44ae-ebe8-baae487aa661"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install tensorboardX\n",
        "%pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tensorboardX import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "## Simple NN. You can change this if you want.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "\n",
        "        self.layer1 = nn.Linear(28*28, 50)\n",
        "        self.layer2 = nn.Linear(50, 50)\n",
        "        self.layer3 = nn.Linear(50, 50)\n",
        "        self.layer4 = nn.Linear(50, 10)\n",
        "\n",
        "        self.nn = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          self.layer1,\n",
        "          nn.ReLU(),\n",
        "          self.layer2,\n",
        "          nn.ReLU(),\n",
        "          self.layer3,\n",
        "          nn.ReLU(),\n",
        "          self.layer4,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.nn.forward(x)\n",
        "\n",
        "    def box_forward_linear(self, Ltensor, Utensor, layer):\n",
        "      Ltensor_forward = layer.forward(Ltensor)\n",
        "      Utensor_forward = layer.forward(Utensor)\n",
        "\n",
        "      return torch.minimum(Ltensor_forward, Utensor_forward), torch.maximum(Ltensor_forward, Utensor_forward)\n",
        "\n",
        "    def box_forward_relu(self, Ltensor, Utensor):\n",
        "      return nn.ReLU().forward(Ltensor), nn.ReLU().forward(Utensor)\n",
        "\n",
        "    def box_forward(self, Ltensor, Utensor):\n",
        "      Ltensor = nn.Flatten().forward(Ltensor)\n",
        "      Utensor = nn.Flatten().forward(Utensor)\n",
        "\n",
        "      Ltensor, Utensor = self.box_forward_linear(Ltensor, Utensor, self.layer1)\n",
        "      Ltensor, Utensor = self.box_forward_relu(Ltensor, Utensor)\n",
        "\n",
        "      Ltensor, Utensor = self.box_forward_linear(Ltensor, Utensor, self.layer2)\n",
        "      Ltensor, Utensor = self.box_forward_relu(Ltensor, Utensor)\n",
        "\n",
        "      Ltensor, Utensor = self.box_forward_linear(Ltensor, Utensor, self.layer3)\n",
        "      Ltensor, Utensor = self.box_forward_relu(Ltensor, Utensor)\n",
        "\n",
        "      Ltensor, Utensor = self.box_forward_linear(Ltensor, Utensor, self.layer4)\n",
        "\n",
        "      return Ltensor, Utensor\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# Add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "model = nn.Sequential(Normalize(), Net())\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHFrznT3fOb4",
        "outputId": "1d1dfbab-d528-4cb6-a6e8-178f393e91ce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Normalize()\n",
              "  (1): Net(\n",
              "    (layer1): Linear(in_features=784, out_features=50, bias=True)\n",
              "    (layer2): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (layer3): Linear(in_features=50, out_features=50, bias=True)\n",
              "    (layer4): Linear(in_features=50, out_features=10, bias=True)\n",
              "    (nn): Sequential(\n",
              "      (0): Flatten(start_dim=1, end_dim=-1)\n",
              "      (1): Linear(in_features=784, out_features=50, bias=True)\n",
              "      (2): ReLU()\n",
              "      (3): Linear(in_features=50, out_features=50, bias=True)\n",
              "      (4): ReLU()\n",
              "      (5): Linear(in_features=50, out_features=50, bias=True)\n",
              "      (6): ReLU()\n",
              "      (7): Linear(in_features=50, out_features=10, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs, enable_defense=False, epsilon=None):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tot_steps = 0\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        t1 = time.time()\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            tot_steps += 1\n",
        "            opt.zero_grad()\n",
        "            if not enable_defense:\n",
        "              out = model(x_batch)\n",
        "              batch_loss = ce_loss(out, y_batch)\n",
        "              batch_loss.backward()\n",
        "            else:\n",
        "              xmin = x_batch - epsilon\n",
        "              xmax = x_batch + epsilon\n",
        "\n",
        "              outL, outU = model.box_forward(xmin, xmax)\n",
        "              # max of incorrect and min of correct\n",
        "\n",
        "              for i in range(len(outU)):\n",
        "                outU[i, y_batch[i]] = outL[i, y_batch[i]]\n",
        "\n",
        "              out = outU\n",
        "\n",
        "              batch_loss = ce_loss(out, y_batch)\n",
        "              batch_loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tot_test, tot_acc = 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "\n",
        "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))"
      ],
      "metadata": {
        "id": "MuyG349ofn3m"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "train_model(model, 10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sPFk2y1fvNx",
        "outputId": "137adc13-bb20-49f3-a7f7-d0176150cb27"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy 0.85570 [13.69 seconds]\n",
            "Epoch 2: Accuracy 0.89720 [8.86 seconds]\n",
            "Epoch 3: Accuracy 0.90810 [8.41 seconds]\n",
            "Epoch 4: Accuracy 0.91590 [9.10 seconds]\n",
            "Epoch 5: Accuracy 0.92170 [9.13 seconds]\n",
            "Epoch 6: Accuracy 0.92790 [8.36 seconds]\n",
            "Epoch 7: Accuracy 0.93070 [8.76 seconds]\n",
            "Epoch 8: Accuracy 0.93580 [8.94 seconds]\n",
            "Epoch 9: Accuracy 0.93850 [9.51 seconds]\n",
            "Epoch 10: Accuracy 0.93930 [8.24 seconds]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The network is now implemented, we can run Box analysis using `network.box_forward()` and passing in the lower and upper values of the box as tensors. We define the robustness as =1 for an example if no adversarial examples exist within the L-infinity ball of size epsilon (as provable by Box), and =0 otherwise. We will look at the average robustness over the training dataset."
      ],
      "metadata": {
        "id": "XwBil5Pyk9mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_robustness(epsilon, model, test_loader):\n",
        "  tot_acc = 0\n",
        "  tot_test = 0\n",
        "\n",
        "  for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "    out = model(x_batch)\n",
        "    pred = torch.max(out, dim=1)[1]\n",
        "\n",
        "    Ltensor = x_batch - epsilon\n",
        "    Utensor = x_batch + epsilon\n",
        "\n",
        "    acc = pred.eq(y_batch).sum().item()\n",
        "\n",
        "    Lbox, Ubox = model.box_forward(Ltensor, Utensor)\n",
        "\n",
        "    Lcorrect = Lbox[:,torch.argmax(out, dim=1)][1]\n",
        "    jcorrect = torch.argmax(out, dim=1)\n",
        "    Uother = Ubox\n",
        "\n",
        "    for i in range(len(Lcorrect)):\n",
        "      proved = True\n",
        "      for j in range(Uother.shape[1]):\n",
        "        if jcorrect[i] == j:\n",
        "          continue\n",
        "        if Uother[i, j] >= Lcorrect[i]:\n",
        "          proved = False\n",
        "      if proved:\n",
        "        tot_acc += 1\n",
        "\n",
        "    tot_test += x_batch.size()[0]\n",
        "\n",
        "  print('Epoch NA: Accuracy %.5lf' % (tot_acc/tot_test))"
      ],
      "metadata": {
        "id": "wCNw8PE-lMBF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "i = 0.01\n",
        "while i <= 0.1:\n",
        "  measure_robustness(i, model, train_loader)\n",
        "  i += 0.01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zjuE_xQl_bu",
        "outputId": "31e422bc-cea8-40ef-893d-287b78d92d66"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch NA: Accuracy 0.16957\n",
            "Epoch NA: Accuracy 0.16123\n",
            "Epoch NA: Accuracy 0.14982\n",
            "Epoch NA: Accuracy 0.13988\n",
            "Epoch NA: Accuracy 0.13195\n",
            "Epoch NA: Accuracy 0.12767\n",
            "Epoch NA: Accuracy 0.11668\n",
            "Epoch NA: Accuracy 0.11543\n",
            "Epoch NA: Accuracy 0.10300\n",
            "Epoch NA: Accuracy 0.09772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now implement robust training using Box and compare the results."
      ],
      "metadata": {
        "id": "w3C--V9dAybc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0.01\n",
        "while i <= 0.1:\n",
        "  model = Net()\n",
        "  model = model.to(device)\n",
        "  train_model(model, 10, True, i)\n",
        "  model.eval()\n",
        "  measure_robustness(i, model, train_loader)\n",
        "  i += 0.01\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVid_dcdA2pX",
        "outputId": "ea80eee0-ae5c-402e-d9e9-dca7b2d979f2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Accuracy 0.84830 [13.31 seconds]\n",
            "Epoch 2: Accuracy 0.88320 [13.50 seconds]\n",
            "Epoch 3: Accuracy 0.90150 [13.61 seconds]\n",
            "Epoch 4: Accuracy 0.91090 [13.44 seconds]\n",
            "Epoch 5: Accuracy 0.91960 [13.54 seconds]\n",
            "Epoch 6: Accuracy 0.92490 [13.58 seconds]\n",
            "Epoch 7: Accuracy 0.93200 [13.59 seconds]\n",
            "Epoch 8: Accuracy 0.93540 [13.37 seconds]\n",
            "Epoch 9: Accuracy 0.93830 [13.47 seconds]\n",
            "Epoch 10: Accuracy 0.94010 [13.44 seconds]\n",
            "Epoch NA: Accuracy 0.17613\n",
            "Epoch 1: Accuracy 0.85940 [13.27 seconds]\n",
            "Epoch 2: Accuracy 0.89490 [13.19 seconds]\n",
            "Epoch 3: Accuracy 0.90910 [13.33 seconds]\n",
            "Epoch 4: Accuracy 0.91460 [13.29 seconds]\n",
            "Epoch 5: Accuracy 0.92150 [13.40 seconds]\n",
            "Epoch 6: Accuracy 0.92770 [13.30 seconds]\n",
            "Epoch 7: Accuracy 0.93110 [13.48 seconds]\n",
            "Epoch 8: Accuracy 0.93410 [13.66 seconds]\n",
            "Epoch 9: Accuracy 0.93870 [13.25 seconds]\n",
            "Epoch 10: Accuracy 0.94110 [13.18 seconds]\n",
            "Epoch NA: Accuracy 0.18318\n",
            "Epoch 1: Accuracy 0.86540 [13.44 seconds]\n",
            "Epoch 2: Accuracy 0.89980 [13.79 seconds]\n",
            "Epoch 3: Accuracy 0.91160 [13.61 seconds]\n",
            "Epoch 4: Accuracy 0.91950 [13.35 seconds]\n",
            "Epoch 5: Accuracy 0.92450 [13.25 seconds]\n",
            "Epoch 6: Accuracy 0.93160 [13.41 seconds]\n",
            "Epoch 7: Accuracy 0.93510 [13.21 seconds]\n",
            "Epoch 8: Accuracy 0.93550 [13.26 seconds]\n",
            "Epoch 9: Accuracy 0.94130 [13.26 seconds]\n",
            "Epoch 10: Accuracy 0.94490 [13.31 seconds]\n",
            "Epoch NA: Accuracy 0.18412\n",
            "Epoch 1: Accuracy 0.86300 [13.21 seconds]\n",
            "Epoch 2: Accuracy 0.89460 [13.23 seconds]\n",
            "Epoch 3: Accuracy 0.90770 [13.19 seconds]\n",
            "Epoch 4: Accuracy 0.91480 [13.30 seconds]\n",
            "Epoch 5: Accuracy 0.92080 [13.14 seconds]\n",
            "Epoch 6: Accuracy 0.92280 [13.26 seconds]\n",
            "Epoch 7: Accuracy 0.92730 [13.31 seconds]\n",
            "Epoch 8: Accuracy 0.92990 [13.50 seconds]\n",
            "Epoch 9: Accuracy 0.93240 [13.59 seconds]\n",
            "Epoch 10: Accuracy 0.93680 [13.35 seconds]\n",
            "Epoch NA: Accuracy 0.19988\n",
            "Epoch 1: Accuracy 0.86960 [13.33 seconds]\n",
            "Epoch 2: Accuracy 0.90020 [13.29 seconds]\n",
            "Epoch 3: Accuracy 0.91110 [13.37 seconds]\n",
            "Epoch 4: Accuracy 0.91970 [13.62 seconds]\n",
            "Epoch 5: Accuracy 0.92750 [13.50 seconds]\n",
            "Epoch 6: Accuracy 0.93120 [13.25 seconds]\n",
            "Epoch 7: Accuracy 0.93300 [13.38 seconds]\n",
            "Epoch 8: Accuracy 0.93920 [13.11 seconds]\n",
            "Epoch 9: Accuracy 0.94160 [13.27 seconds]\n",
            "Epoch 10: Accuracy 0.94490 [13.25 seconds]\n",
            "Epoch NA: Accuracy 0.17822\n",
            "Epoch 1: Accuracy 0.86380 [13.85 seconds]\n",
            "Epoch 2: Accuracy 0.89790 [13.66 seconds]\n",
            "Epoch 3: Accuracy 0.91060 [13.29 seconds]\n",
            "Epoch 4: Accuracy 0.91960 [13.36 seconds]\n",
            "Epoch 5: Accuracy 0.92420 [13.18 seconds]\n",
            "Epoch 6: Accuracy 0.93040 [13.26 seconds]\n",
            "Epoch 7: Accuracy 0.93410 [13.51 seconds]\n",
            "Epoch 8: Accuracy 0.93650 [13.49 seconds]\n",
            "Epoch 9: Accuracy 0.93940 [13.93 seconds]\n",
            "Epoch 10: Accuracy 0.94190 [13.67 seconds]\n",
            "Epoch NA: Accuracy 0.18067\n",
            "Epoch 1: Accuracy 0.86070 [13.49 seconds]\n",
            "Epoch 2: Accuracy 0.89820 [13.60 seconds]\n",
            "Epoch 3: Accuracy 0.90990 [14.15 seconds]\n",
            "Epoch 4: Accuracy 0.91830 [14.18 seconds]\n",
            "Epoch 5: Accuracy 0.92390 [13.65 seconds]\n",
            "Epoch 6: Accuracy 0.92890 [13.77 seconds]\n",
            "Epoch 7: Accuracy 0.93330 [13.75 seconds]\n",
            "Epoch 8: Accuracy 0.93590 [14.01 seconds]\n",
            "Epoch 9: Accuracy 0.93990 [13.79 seconds]\n",
            "Epoch 10: Accuracy 0.94350 [13.59 seconds]\n",
            "Epoch NA: Accuracy 0.18708\n",
            "Epoch 1: Accuracy 0.87600 [13.72 seconds]\n",
            "Epoch 2: Accuracy 0.89590 [13.60 seconds]\n",
            "Epoch 3: Accuracy 0.90740 [13.56 seconds]\n",
            "Epoch 4: Accuracy 0.91580 [13.55 seconds]\n",
            "Epoch 5: Accuracy 0.92290 [14.19 seconds]\n",
            "Epoch 6: Accuracy 0.92830 [13.77 seconds]\n",
            "Epoch 7: Accuracy 0.93140 [13.51 seconds]\n",
            "Epoch 8: Accuracy 0.93360 [13.58 seconds]\n",
            "Epoch 9: Accuracy 0.94140 [13.57 seconds]\n",
            "Epoch 10: Accuracy 0.94280 [13.68 seconds]\n",
            "Epoch NA: Accuracy 0.18353\n",
            "Epoch 1: Accuracy 0.84970 [13.53 seconds]\n",
            "Epoch 2: Accuracy 0.89600 [13.69 seconds]\n",
            "Epoch 3: Accuracy 0.91060 [13.84 seconds]\n",
            "Epoch 4: Accuracy 0.92120 [13.58 seconds]\n",
            "Epoch 5: Accuracy 0.92320 [13.54 seconds]\n",
            "Epoch 6: Accuracy 0.93050 [13.82 seconds]\n",
            "Epoch 7: Accuracy 0.93250 [13.82 seconds]\n",
            "Epoch 8: Accuracy 0.93640 [14.32 seconds]\n",
            "Epoch 9: Accuracy 0.93950 [13.53 seconds]\n",
            "Epoch 10: Accuracy 0.94280 [13.51 seconds]\n",
            "Epoch NA: Accuracy 0.18643\n",
            "Epoch 1: Accuracy 0.86320 [13.82 seconds]\n",
            "Epoch 2: Accuracy 0.89190 [13.93 seconds]\n",
            "Epoch 3: Accuracy 0.90530 [13.62 seconds]\n",
            "Epoch 4: Accuracy 0.91350 [13.69 seconds]\n",
            "Epoch 5: Accuracy 0.92120 [13.82 seconds]\n",
            "Epoch 6: Accuracy 0.92760 [13.62 seconds]\n",
            "Epoch 7: Accuracy 0.93410 [13.60 seconds]\n",
            "Epoch 8: Accuracy 0.93660 [13.49 seconds]\n",
            "Epoch 9: Accuracy 0.94000 [13.61 seconds]\n",
            "Epoch 10: Accuracy 0.94230 [14.26 seconds]\n",
            "Epoch NA: Accuracy 0.19177\n"
          ]
        }
      ]
    }
  ]
}